---
title: "data preparation task 1"
author: "Frederik Bennhoff"
date: "2023-11-10"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = '../')
```

# Load Data & Packages

The purpose of this markdown document is to explore and clean data for the first submission task for the class *Advanced Machine Learning*.

```{r, label = "import libraries"}
rm(list = ls())
require(tidyverse)
require(glmnet)
```

```{r, label = "load data"}
#path = "~/git/aml_course/project_1"
#setwd("../")
dir.create('data/processed/', showWarnings = F)

load_data = function(){
  X_test <<- read_csv("./data/X_test.csv")
  X_train <<- read_csv("./data/X_train.csv")
  Y_train <<- read_csv("./data/Y_train.csv")  
}
load_data()
```

# Data Preparation

Define functions for later use.

```{r, label = "declare utility functions"}
# function to print the share of NA observations.
na_share = function(x) {
  bool = is.na(x)
  sum(bool)/length(bool)
}

# function to print the count of NA observations.
na_count = function(x) {
  bool = is.na(x)
  sum(bool)
}

# Apply the Hampel filter for outlier detection, return counts
outlier_count = function(x, g) {
  med = median(x, na.rm = T)
  mad = median( abs(x - med), na.rm = T )
  hampel_lower = med - g * mad
  hampel_upper = med + g * mad
  
  bool = (x > hampel_upper) | (x < hampel_lower)
  
  sum(bool, na.rm = T)  
}

# Apply the Hampel filter for outlier detection, return IDs
outlier_ids = function(x, g, origin, type = 'both') {
  med = median(x[origin == "train"], na.rm = T)
  mad = median( abs(x[origin == "train"] - med), na.rm = T )
  hampel_lower = med - g * mad
  hampel_upper = med + g * mad
  
  if (type == 'both') {
    bool = (x > hampel_upper) | (x < hampel_lower)
  } 
  else if (type == 'left') {
    bool = (x < hampel_lower)
  } else {
    bool = (x > hampel_upper)
  }
  return(which(bool))
}

# function to generate an indicator variable that shows whether a value is an outlier
generate_indicators_for_outliers = function(x, g, origin, type = 'both') {
  ids = outlier_ids(x, g, origin, type)
  x_outlier = vector(length=length(x))
  x_outlier[ids] = 1
  return(x_outlier)
}

# function to winsorize variable when taking outlier values
winsorize_outliers = function(x, g, origin) {
  med = median(x[origin == "train"], na.rm = T)
  mad = median( abs(x[origin == "train"] - med), na.rm = T )
  hampel_lower = med - g * mad
  hampel_upper = med + g * mad
  
  x[x > hampel_upper] = hampel_upper 
  x[x < hampel_lower] = hampel_lower
  return(x)
}

# take the whole dataset and create a bunch of indicator variables for outliers (if enough outliers)
generate_outlier_variables = function(data, g, threshold, types = c('both'), origin) {
  temp_data = data
  for (i in 2:ncol(data)) {
    for (type in types) {
      name_str = paste0(colnames(data)[i], "_out", "_", type)
      temp_var = generate_indicators_for_outliers(pull(data, i), g, origin, type)
      if (sum(temp_var) > threshold) {
        temp_data = add_column(temp_data, new_column = temp_var )  
        colnames(temp_data)[ncol(temp_data)] = name_str
      }
    }    
  }
  return(temp_data)
}


# impute median value for missings
impute_median = function(x, origin) {
  med = median(x[origin == "train"], na.rm = T)
  x[is.na(x)] = med  
  return(x)
}

# standardize a column
standardize = function(x, origin, robust = F) {

  if (robust == T) {
    iqr = IQR(x[origin == "train"], na.rm = T)
    if (iqr == 0) {
      return(NULL)
    }
    temp = (x - median(x[origin == "train"], na.rm = T)) / iqr
    return(temp)  
  }
  
  sdev = sd(x[origin == "train"], na.rm = T)
  if (sdev == 0) {
    return(NULL)
  }
  temp = (x - mean(x[origin == "train"], na.rm = T)) / sdev
  return(temp)
}
```

We obtain a summary table for each variable, to eyeball outlier counts and \# of missing values.

```{r, label = "generate a summary table for outliers and missingness"}
summ_table = gather(X_train[, 2:833]) %>% group_by(key) %>% summarise(
    mean = mean(value, na.rm = T),
    sd = sd(value, na.rm = T),
    outlier_count = outlier_count(value, 4),
    #outlier_ids = outlier_ids(value, 4),
    na_count = na_count(value)
    )
```

We see that the distribution of extreme values with respect to the Hampel filter is extremely skewed. The problem here is that we cannot just delete outliers even if the filter applies a very loose criterion (i.e. large $g$), because some variables are highly skewed and thus too many observations are classified as outliers. On the other hand, the NA shares appear to be normally distributed across variables.

```{r, label = "render outlier and NA histograms"}
par(mfrow = c(1, 2))
hist(summ_table$outlier_count, main = "Histogram of outlier counts", xlab = "# outliers in a variable")

hist(summ_table$na_count/length(X_train$id), main = "Histogram of NA shares", xlab = "share NAs in a variable")

par(mfrow = c(1, 1))

```

**Outliers:** We thus do following things to deal with outliers:

1.  We standardize columns
2.  We create indicator variables that take the value 1 if an observation is an right (left) outlier with respect to the Hampel filter. Set the value of the filter to a typical value of 3.
3.  We winsorize variables above the outlier threshold.

However, in out final model, we additionally do a quantile transformation on all variables

**Missing Values**: We impute missing values with the median value of each variable.

```{r}
# g = 3 # Hampel filter value for outlier classification
# threshold = 1 # minimum value of outliers to create indicator
# 
# # drop columns without any variation in them
# has_variation = X_train %>% map_vec(function(x){sd(x, na.rm = T)}) > 0
# X_train = X_train[, has_variation]
# X_test  = X_test[, has_variation]
# 
# # save column names of untransformed dataset
# init_names = colnames(X_train)
# init_names = init_names[2:length(init_names)]
# 
# ## prepare training data
# # standardize columns
# X_train[2:ncol(X_train)] <- map(X_train[2:ncol(X_train)], function(x){standardize(x, T)}) %>% as_tibble
# # generate outlier variables and add to dataset
# X_train = generate_outlier_variables(X_train, g, threshold, c('left', 'right'))
# # winsorize outliers
# X_train[init_names] = X_train[init_names] %>% map(function(x){winsorize_outliers(x,g)})
# # impute medians
# X_train = map(X_train, impute_median) %>% as_tibble
# 
# ## prepare test data
# X_test[2:ncol(X_test)] <- map(X_test[2:ncol(X_test)], standardize) %>% as_tibble
# X_test = generate_outlier_variables(X_test, g, threshold, c('left', 'right')) 
# X_test[init_names] = X_test[init_names] %>% map(function(x){winsorize_outliers(x,g)})
# X_test = map(X_test, impute_median) %>% as_tibble 


```

```{r, label = 'append training and test data for data transformation'}
# append test and training data and add a column indicating data origin
# reson: easier to fit data transformation to "train" data and apply them to "test" data
X_test$origin = "test"
X_train$origin = "train"
X_full = add_row(X_test, X_train)
origin = X_full$origin # sample origin vector
X_full = X_full %>% select( -c("origin")) # drop origin column

```

```{r, label = "create outlier indicators, winsorize outliers, impute median values"}
g = 3 # Hampel filter value for outlier classification
threshold = 1 # minimum value of outliers to create indicator

# drop columns without any variation in the training data
has_variation = X_full %>% map_vec(function(x){sd(x[origin == "train"], na.rm = T)}) > 0
X_full = X_full[, has_variation]

# save column names of untransformed dataset
init_names = colnames(X_full)
init_names = init_names[2:length(init_names)]

## prepare training data
# standardize columns
X_full[2:ncol(X_full)] <- map(X_full[2:ncol(X_full)], function(x){standardize(x, origin, T)}) %>% as_tibble
# generate outlier variables and add to dataset
X_full = generate_outlier_variables(X_full, g, threshold, c('left', 'right'), origin)
# winsorize outliers
X_full[init_names] = X_full[init_names] %>% map(function(x){winsorize_outliers(x, g, origin)})
# impute medians
X_full = map(X_full, function(x){impute_median(x, origin)}) %>% as_tibble
```

```{r, label = 'split up data again'}
X_test = X_full[origin == "test",]
X_train = X_full[origin == "train",]
```

```{r, label = "export data"}
## export data
write_csv(X_test, "./data/processed/X_test.csv")
write_csv(X_train, "./data/processed/X_train.csv")
write_csv(Y_train, "./data/processed/Y_train.csv")
```
