{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Train ResNet Models on ECG Image Data \n",
    "author: Frederik Bennhoff\n",
    "date: 01/12/2023\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "folder_name = \"spectrograms_256\"\n",
    "valid_pct = 0.1\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries and set path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.all import *\n",
    "from shutil import rmtree\n",
    "from fastai.vision.all import *\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# set seed\n",
    "np.random.seed(seed)\n",
    "\n",
    "# set up folder\n",
    "p = Path('../data/'+folder_name) # relative path to folder with images\n",
    "p_out = Path('../out/'+folder_name) # relative path to output folder\n",
    "p_out.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function definitions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_df(folder_name):\n",
    "    files_df = pd.DataFrame([], columns=[\"filename\", \"id\", \"sequence\", \"label\"])\n",
    "    for type in range(4):\n",
    "        # Get a list of all filenames in the folder\n",
    "        folder_path = f'../data/{folder_name}/{type}/'  # replace with your folder path\n",
    "        filenames = os.listdir(folder_path)\n",
    "\n",
    "        # Create a DataFrame from the list\n",
    "        df = pd.DataFrame(filenames, columns=['filename'])\n",
    "\n",
    "        # Split the 'filename' column on '_'\n",
    "        df[['sg', 'id', 'sequence']] = df['filename'].str.split('_', expand=True)\n",
    "\n",
    "        # Split the 'number2' column on '.' to remove the file extension\n",
    "        df['sequence'] = df['sequence'].str.split('.', expand=True)[0]\n",
    "\n",
    "        df.sort_values(by=['id', 'sequence'], inplace=True)\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "        df[\"label\"] = type\n",
    "        df = df[df.sg == \"sg\"]\n",
    "        df.drop(columns=[\"sg\"], inplace=True)\n",
    "        df['id'] = df['id'].to_numpy(dtype=int)\n",
    "        df['sequence'] = df['sequence'].to_numpy(dtype=int)\n",
    "        files_df = pd.concat([files_df, df], ignore_index=True)\n",
    "    \n",
    "    files_df.sort_values(by=['id', 'sequence'], inplace=True)\n",
    "    files_df.reset_index(inplace=True, drop=True)\n",
    "    files_df.reset_index(drop=True)\n",
    "    \n",
    "    return files_df\n",
    "\n",
    "def get_df_for_model(folder_name, valid_pct):\n",
    "    files_df = get_files_df(folder_name)\n",
    "    # sample fraction 'valid_pct' of ids for validation sample\n",
    "    ids = files_df.id.unique()\n",
    "    valid_ids = np.random.choice(ids, int(len(ids)*valid_pct), replace=False)\n",
    "    bool = [id in valid_ids for id in files_df.id]\n",
    "    files_df[\"is_valid\"] = bool\n",
    "    files_df[\"filename\"] = files_df.label.apply(lambda x: str(x)) + \"/\" + files_df[\"filename\"]\n",
    "    return files_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for failed images (not an issue, so not active)\n",
    "#resize_images(p/\"0\", max_size=400, dest = p/\"0\") # resize images\n",
    "# failed = verify_images(get_image_files(p/\"0\")) # verify images\n",
    "# failed.map(Path.unlink) # delete failed images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data loader and look at some of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df = get_df_for_model(folder_name, valid_pct)\n",
    "dls = ImageDataLoaders.from_df(\n",
    "    files_df, \n",
    "    path=p,\n",
    "    label_col=\"label\",\n",
    "    valid_col=\"is_valid\", \n",
    "    item_tfms=Resize(224)\n",
    "    );\n",
    "dls.show_batch(max_n=6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit resnet50 model, full fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, \n",
    "                       resnet50,\n",
    "                       metrics=error_rate\n",
    "                       )\n",
    "\n",
    "learn.fit_one_cycle(10)\n",
    "learn.recorder.plot_loss()\n",
    "\n",
    "# save model\n",
    "learn.path = p_out\n",
    "learn.save('resnet50-10_fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune resnet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, \n",
    "                       resnet50,\n",
    "                       metrics=error_rate\n",
    "                       )\n",
    "\n",
    "learn.fine_tune(10)\n",
    "learn.recorder.plot_loss()\n",
    "\n",
    "# save model\n",
    "learn.path = p_out\n",
    "learn.save('resnet50-10_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit resnet18 model, full fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, \n",
    "                       resnet18,\n",
    "                       metrics=error_rate\n",
    "                       )\n",
    "\n",
    "learn.fit_one_cycle(20)\n",
    "learn.recorder.plot_loss()\n",
    "\n",
    "# save model\n",
    "learn.path = p_out\n",
    "learn.save('resnet18-20_fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune resnet18 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, \n",
    "                       resnet18,\n",
    "                       metrics=error_rate\n",
    "                       )\n",
    "\n",
    "learn.fine_tune(6)\n",
    "learn.recorder.plot_loss()\n",
    "\n",
    "# save model\n",
    "learn.path = p_out\n",
    "learn.save('resnet18-6_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show results of last training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "We have multiple samples for each patient. We will aggregate the predictions for each patient using Bayes' rule and predict the class with the highest posterior probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inter = Interpretation.from_learner(learn, dl = dls[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df[files_df.is_valid == True].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_prob, pred_class = learn.get_preds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.concat([\n",
    "    files_df[files_df.is_valid == True].reset_index(drop=True),\n",
    "    pd.DataFrame(pred_prob.numpy(), columns=[\"p_0\", \"p_1\", \"p_2\", \"p_3\"]),\n",
    "    pd.DataFrame(pred_class.numpy(), columns=[\"pred_class\"])\n",
    "], axis=1)\n",
    "max_cat = predictions_df.groupby(\"id\").agg({\"p_0\": \"mean\", \"p_1\": \"mean\", \"p_2\": \"mean\", \"p_3\": \"mean\"}).apply(lambda x: x.argmax(), axis=1).reset_index(drop=True);\n",
    "mean_probs = predictions_df.groupby(\"id\").agg({\"p_0\": \"mean\", \"p_1\": \"mean\", \"p_2\": \"mean\", \"p_3\": \"mean\"}).reset_index()\n",
    "predictions = pd.concat([mean_probs, max_cat], axis=1)\n",
    "predictions.columns = [\"id\", \"p_0\", \"p_1\", \"p_2\", \"p_3\", \"pred_class\"]\n",
    "predictions = pd.merge(files_df[files_df.is_valid == True],predictions, on=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions[\"label\"].to_numpy(dtype=np.int32)), len(predictions[\"pred_class\"].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(predictions[\"label\"].to_numpy(dtype=np.int32), predictions[\"pred_class\"].to_numpy(dtype=np.int32), average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df[files_df[\"label\"]==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "learn.load('resnet18-20_fit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "\n",
    "def open_image(fname, size=224):\n",
    "    img = PIL.Image.open(fname).convert('RGB')\n",
    "    img = img.resize((size, size))\n",
    "    t = torch.Tensor(np.array(img))\n",
    "    return t.permute(2,0,1).float()/255.0\n",
    "\n",
    "# Make a prediction\n",
    "img = PILImage.create(p/files_df.filename[0])  # replace with the path to your image\n",
    "pred_class, pred_idx, probs = learn.predict(img)\n",
    "\n",
    "print(pred_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.show(title=f'This food is {label} with probability {probs[0]:.4f}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.predict(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
