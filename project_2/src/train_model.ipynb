{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Train ResNet Models on ECG Image Data \n",
    "author: Frederik Bennhoff\n",
    "date: 01/12/2023\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "folder_name = \"spectrograms_128\"\n",
    "valid_pct = 0.1\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import libraries and set path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.all import *\n",
    "from shutil import rmtree\n",
    "from fastai.vision.all import *\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# set seed\n",
    "np.random.seed(seed)\n",
    "\n",
    "# set up folder\n",
    "os.chdir(\"src\") # change to src folder\n",
    "p = Path('../data/'+folder_name) # relative path to folder with images\n",
    "p_out = Path('../out/'+folder_name) # relative path to output folder\n",
    "p_out.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function definitions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For loading training data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_df(folder_name, prefix):\n",
    "    files_df = pd.DataFrame([], columns=[\"filename\", \"id\", \"sequence\", \"label\"])\n",
    "    for type in range(4):\n",
    "        # Get a list of all filenames in the folder\n",
    "        folder_path = f'../data/{folder_name}/{type}/'  # replace with your folder path\n",
    "        filenames = os.listdir(folder_path)\n",
    "\n",
    "        # Create a DataFrame from the list\n",
    "        df = pd.DataFrame(filenames, columns=['filename'])\n",
    "\n",
    "        # Split the 'filename' column on '_'\n",
    "        df[['sg', 'id', 'sequence']] = df['filename'].str.split('_', expand=True)\n",
    "\n",
    "        # Split the 'number2' column on '.' to remove the file extension\n",
    "        df['sequence'] = df['sequence'].str.split('.', expand=True)[0]\n",
    "\n",
    "        df.sort_values(by=['id', 'sequence'], inplace=True)\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "        df[\"label\"] = type\n",
    "        df = df[df.sg == prefix]\n",
    "        df.drop(columns=[prefix], inplace=True)\n",
    "        df['id'] = df['id'].to_numpy(dtype=int)\n",
    "        df['sequence'] = df['sequence'].to_numpy(dtype=int)\n",
    "        files_df = pd.concat([files_df, df], ignore_index=True)\n",
    "    \n",
    "    files_df.sort_values(by=['id', 'sequence'], inplace=True)\n",
    "    files_df.reset_index(inplace=True, drop=True)\n",
    "    files_df.reset_index(drop=True)\n",
    "    \n",
    "    return files_df\n",
    "\n",
    "def get_df_for_model(folder_name, prefix, valid_pct):\n",
    "    files_df = get_files_df(folder_name, prefix)\n",
    "    # sample fraction 'valid_pct' of ids for validation sample\n",
    "    ids = files_df.id.unique()\n",
    "    valid_ids = np.random.choice(ids, int(len(ids)*valid_pct), replace=False)\n",
    "    bool = [id in valid_ids for id in files_df.id]\n",
    "    files_df[\"is_valid\"] = bool\n",
    "    files_df[\"filename\"] = files_df.label.apply(lambda x: str(x)) + \"/\" + files_df[\"filename\"]\n",
    "    return files_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*For predicting validation data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_predictions_on_validation_set(pred_prob, pred_class, files_df):\n",
    "        \n",
    "    predictions_df = pd.concat([\n",
    "        files_df[files_df.is_valid == True].reset_index(drop=True),\n",
    "        pd.DataFrame(pred_prob.numpy(), columns=[\"p_0\", \"p_1\", \"p_2\", \"p_3\"]),\n",
    "        pd.DataFrame(pred_class.numpy(), columns=[\"pred_label\"])\n",
    "    ], axis=1)\n",
    "    max_cat = predictions_df.groupby(\"id\").agg({\"p_0\": \"mean\", \"p_1\": \"mean\", \"p_2\": \"mean\", \"p_3\": \"mean\"}).apply(lambda x: x.argmax(), axis=1).reset_index(drop=True);\n",
    "    mean_probs = predictions_df.groupby(\"id\").agg({\"p_0\": \"mean\", \"p_1\": \"mean\", \"p_2\": \"mean\", \"p_3\": \"mean\"}).reset_index()\n",
    "    predictions = pd.concat([mean_probs, max_cat], axis=1)\n",
    "    predictions.columns = [\"id\", \"p_0\", \"p_1\", \"p_2\", \"p_3\", \"pred_label\"]\n",
    "    predictions = pd.merge(files_df[files_df.is_valid == True],predictions, on=\"id\")\n",
    "\n",
    "    predictions = predictions[predictions[\"sequence\"]==0] # only keep first sequence\n",
    "    predictions.drop(\"sequence\", axis=1, inplace=True) # drop sequence column\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "def calc_score(predictions_valset):\n",
    "    return f1_score(predictions_valset[\"label\"].to_numpy(dtype=np.int32), predictions_valset[\"pred_label\"].to_numpy(dtype=np.int32), average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for failed images (not an issue, so not active)\n",
    "#resize_images(p/\"0\", max_size=400, dest = p/\"0\") # resize images\n",
    "# failed = verify_images(get_image_files(p/\"0\")) # verify images\n",
    "# failed.map(Path.unlink) # delete failed images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a data loader and look at some of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df = get_df_for_model(folder_name, \"sg\", valid_pct)\n",
    "dls = ImageDataLoaders.from_df(\n",
    "    files_df, \n",
    "    path=p,\n",
    "    label_col=\"label\",\n",
    "    valid_col=\"is_valid\", \n",
    "    item_tfms=Resize(224)\n",
    "    );\n",
    "dls.show_batch(max_n=6);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and evaluate models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit resnet50 model, full fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "learn = vision_learner(dls, \n",
    "                       resnet50,\n",
    "                       metrics=error_rate\n",
    "                       )\n",
    "\n",
    "learn.fit_one_cycle(7)\n",
    "learn.recorder.plot_loss()\n",
    "\n",
    "# save model\n",
    "learn.path = p_out\n",
    "learn.save('resnet50_7_fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation sample predictions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# get predictions on validation set\n",
    "pred_prob, pred_class = learn.get_preds() \n",
    "predictions_valset = aggregate_predictions_on_validation_set(pred_prob, pred_class, files_df)\n",
    "predictions_valset.head(10)\n",
    "print(\"\\n\\nF1 Score:\", calc_score(predictions_valset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune resnet50 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "learn = vision_learner(dls, \n",
    "                       resnet50,\n",
    "                       metrics=error_rate\n",
    "                       )\n",
    "\n",
    "learn.fine_tune(20)\n",
    "learn.recorder.plot_loss()\n",
    "\n",
    "# save model\n",
    "learn.path = p_out\n",
    "learn.save('resnet50_10_tuned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation sample predictions"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# get predictions on validation set\n",
    "pred_prob, pred_class = learn.get_preds() \n",
    "predictions_valset = aggregate_predictions_on_validation_set(pred_prob, pred_class, files_df)\n",
    "predictions_valset.head(20)\n",
    "print(\"\\n\\nF1 Score:\", calc_score(predictions_valset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit resnet18 model, full fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, \n",
    "                       resnet18,\n",
    "                       metrics=error_rate\n",
    "                       )\n",
    "\n",
    "learn.fit_one_cycle(10)\n",
    "learn.recorder.plot_loss()\n",
    "\n",
    "# save model\n",
    "learn.path = p_out\n",
    "learn.save('resnet18_10_fit')\n",
    "torch.save(dls, p_out/\"models/resnet18_10_fit_dls.pkl\") # save dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation sample predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions on validation set\n",
    "pred_prob, pred_class = learn.get_preds() \n",
    "predictions_valset = aggregate_predictions_on_validation_set(pred_prob, pred_class, files_df)\n",
    "predictions_valset.head(20)\n",
    "print(\"\\n\\nF1 Score:\", calc_score(predictions_valset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tune resnet18 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, \n",
    "                       resnet18,\n",
    "                       metrics=error_rate\n",
    "                       )\n",
    "\n",
    "learn.fine_tune(10)\n",
    "learn.recorder.plot_loss()\n",
    "\n",
    "# save model\n",
    "learn.path = p_out\n",
    "learn.save('resnet18_10_tuned') # save model\n",
    "torch.save(dls, p_out/\"models/resnet18_10_tuned_dls.pkl\") # save dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation sample predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions on validation set\n",
    "pred_prob, pred_class = learn.get_preds() \n",
    "predictions_valset = aggregate_predictions_on_validation_set(pred_prob, pred_class, files_df)\n",
    "predictions_valset.head(20)\n",
    "print(\"\\n\\nF1 Score:\", calc_score(predictions_valset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show results of last training run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "We have multiple samples for each patient. We will aggregate the predictions for each patient using a simple average and predict the class with the highest resulting probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions on Test Set**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = \"resnet18_10_fit\"\n",
    "architecture, epochs, approach = model.split(\"_\")\n",
    "folder_name = \"spectrograms_256\"\n",
    "p = Path(\"../out/\"+folder_name)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_files_test_df(folder_name, subfolder_name, prefix):\n",
    "    \"\"\"\n",
    "    Get a DataFrame of test files with their filenames, ids, and sequences.\n",
    "\n",
    "    Parameters:\n",
    "    - folder_name (str): The name of the folder containing the files.\n",
    "    - subfolder_name (str): The name of the subfolder containing the files.\n",
    "    - prefix (str): The prefix used to filter the filenames.\n",
    "\n",
    "    Returns:\n",
    "    - files_df (pd.DataFrame): The DataFrame containing the filenames, ids, and sequences of the test files.\n",
    "    \"\"\"\n",
    "    files_df = pd.DataFrame([], columns=[\"filename\", \"id\", \"sequence\"])\n",
    "    \n",
    "    # Get a list of all filenames in the folder\n",
    "    folder_path = f'../data/{folder_name}/{subfolder_name}/'  # replace with your folder path\n",
    "    filenames = os.listdir(folder_path)\n",
    "\n",
    "    # Create a DataFrame from the list\n",
    "    df = pd.DataFrame(filenames, columns=['filename'])\n",
    "\n",
    "    # Split the 'filename' column on '_'\n",
    "    df[['sg', 'id', 'sequence']] = df['filename'].str.split('_', expand=True)\n",
    "\n",
    "    # Split the 'number2' column on '.' to remove the file extension\n",
    "    df['sequence'] = df['sequence'].str.split('.', expand=True)[0]\n",
    "\n",
    "    df.sort_values(by=['id', 'sequence'], inplace=True)\n",
    "    df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    df = df[df.sg == prefix]\n",
    "    df.drop(columns=[prefix], inplace=True)\n",
    "    df['id'] = df['id'].to_numpy(dtype=int)\n",
    "    df['sequence'] = df['sequence'].to_numpy(dtype=int)\n",
    "    files_df = pd.concat([files_df, df], ignore_index=True)\n",
    "    \n",
    "    files_df.sort_values(by=['id', 'sequence'], inplace=True)\n",
    "    files_df.reset_index(inplace=True, drop=True)\n",
    "    files_df.reset_index(drop=True)\n",
    "\n",
    "    files_df['filename'] = subfolder_name + \"/\" + files_df['filename']\n",
    "    \n",
    "    return files_df\n",
    "\n",
    "def aggregate_predictions_on_test_set(pred_prob, pred_class, files_df):\n",
    "    \"\"\"\n",
    "    Aggregate predictions on the test set.\n",
    "\n",
    "    Parameters:\n",
    "    - pred_prob (numpy.ndarray): Array of predicted probabilities.\n",
    "    - pred_class (numpy.ndarray): Array of predicted classes.\n",
    "    - files_df (pd.DataFrame): DataFrame containing filenames, ids, and sequences.\n",
    "\n",
    "    Returns:\n",
    "    - predictions (pd.DataFrame): DataFrame containing aggregated predictions on the test set.\n",
    "    \"\"\"\n",
    "    predictions_df = pd.concat([\n",
    "        files_df.reset_index(drop=True),\n",
    "        pd.DataFrame(pred_prob, columns=[\"p_0\", \"p_1\", \"p_2\", \"p_3\"]),\n",
    "        pd.DataFrame(pred_class, columns=[\"pred_label\"])\n",
    "    ], axis=1)\n",
    "    max_cat = predictions_df.groupby(\"id\").agg({\"p_0\": \"mean\", \"p_1\": \"mean\", \"p_2\": \"mean\", \"p_3\": \"mean\"}).apply(lambda x: x.argmax(), axis=1).reset_index(drop=True);\n",
    "    mean_probs = predictions_df.groupby(\"id\").agg({\"p_0\": \"mean\", \"p_1\": \"mean\", \"p_2\": \"mean\", \"p_3\": \"mean\"}).reset_index()\n",
    "    predictions = pd.concat([mean_probs, max_cat], axis=1)\n",
    "    predictions.columns = [\"id\", \"p_0\", \"p_1\", \"p_2\", \"p_3\", \"pred_label\"]\n",
    "    predictions = pd.merge(files_df,predictions, on=\"id\")\n",
    "    predictions = predictions[predictions[\"sequence\"]==0] # only keep first sequence\n",
    "    predictions.drop(\"sequence\", axis=1, inplace=True) # drop sequence column\n",
    "    return predictions\n",
    "\n",
    "def get_predictions_testset(p, model, architecture, folder_name, dls):\n",
    "    \"\"\"\n",
    "    Get predictions on the test set using a trained model.\n",
    "\n",
    "    Parameters:\n",
    "    - p (Path): The path to the folder containing the trained model.\n",
    "    - model (str): The name of the trained model.\n",
    "    - architecture (str): The name of the architecture used for the model.\n",
    "    - folder_name (str): The name of the folder containing the test data.\n",
    "\n",
    "    Returns:\n",
    "    - predictions_df (pd.DataFrame): DataFrame containing the predictions on the test set.\n",
    "    \"\"\"\n",
    "    ## load the model\n",
    "    # create learner\n",
    "    learn = vision_learner(dls, \n",
    "                        globals()[architecture],\n",
    "                        metrics=error_rate\n",
    "                        )\n",
    "\n",
    "    # load model\n",
    "    learn.path = p\n",
    "    learn.load(model)\n",
    "\n",
    "    ## get dataframe of test files & dataloader\n",
    "    files_test_df = get_files_test_df(folder_name, \"test\", \"sg\") # obtain a dataframe of test files\n",
    "    test_dl = dls.test_dl(files_test_df) # make dataLoader for test data\n",
    "\n",
    "    ## predict on test set\n",
    "    # step 1: get predictions per sequence\n",
    "    pred_test_prob = learn.get_preds(dl=test_dl) # get predictions for test data\n",
    "    pred_test_prob = pred_test_prob[0].numpy() # convert to numpy array\n",
    "    pred_test_class = np.array([np.argmax(x) for x in pred_test_prob], dtype=np.int32) # get class with highest probability\n",
    "\n",
    "    # step 2: aggregate predictions on test set across ecg 10-sec sequences\n",
    "    predictions_df = aggregate_predictions_on_test_set(pred_test_prob, pred_test_class, files_test_df)\n",
    "\n",
    "    print(\"\\nPredictions on test set:\")\n",
    "    predictions_df.head(10) # show first 10 rows\n",
    "    return predictions_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "predictions = get_predictions_testset(p, model, architecture, folder_name, dls2)\n",
    "\n",
    "(p/\"predictions\").mkdir(parents=True, exist_ok=True)\n",
    "predictions.to_csv(p/\"predictions\"/f\"{model}_testset.csv\", index=False)\n",
    "predictions.columns = [\"filename\", \"id\", \"p_0\", \"p_1\", \"p_2\", \"p_3\", \"y\"]\n",
    "predictions.loc[:,[\"id\", \"y\"]].to_csv(p/\"predictions\"/f\"{model}_testset_submission.csv\", index=False)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions on validation set**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "learn = vision_learner(dls, \n",
    "                       globals()[\"resnet18\"],\n",
    "                       metrics=error_rate\n",
    "                       )\n",
    "\n",
    "# load model\n",
    "learn.path = p_out\n",
    "learn.load('resnet18_10_fit')\n",
    "\n",
    "# get predictions on validation set\n",
    "pred_prob, pred_class = learn.get_preds() \n",
    "predictions_valset = aggregate_predictions_on_validation_set(pred_prob, pred_class, files_df)\n",
    "predictions_valset.head(10)\n",
    "print(\"\\n\\nF1 Score:\", calc_score(predictions_valset))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
